{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.signal import find_peaks\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "PEAK_THRESHOLD = 390\n",
    "DATA_PATH = \"./data/exported/1min/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sitting data load\n",
    "with gzip.open(DATA_PATH + \"sitting_ecg.pkl\", \"rb\") as f:\n",
    "    sitting_ecg = pickle.load(f)\n",
    "\n",
    "with gzip.open(DATA_PATH + \"sitting_acc.pkl\", \"rb\") as f:\n",
    "    sitting_acc = pickle.load(f)\n",
    "sitting_acc = sitting_acc - np.mean(sitting_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(sitting_acc), 1, figsize=(20, 10))\n",
    "for idx in range(len(sitting_acc)):\n",
    "    peaks, _ = find_peaks(sitting_acc[idx], height=PEAK_THRESHOLD)\n",
    "    np.diff(peaks)\n",
    "\n",
    "    ax[idx].plot(sitting_acc[idx])\n",
    "    ax[idx].plot(peaks, sitting_acc[idx][peaks], \"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_list = list()\n",
    "for idx in range(len(sitting_acc)):\n",
    "    peaks, _ = find_peaks(sitting_acc[idx], height=PEAK_THRESHOLD)\n",
    "    if peaks == []:\n",
    "        peak_list.append(np.array([0]))\n",
    "    peak_list.append(len(peaks))\n",
    "\n",
    "X_sitting = sitting_ecg\n",
    "y_sitting = peak_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walking data load\n",
    "with gzip.open(DATA_PATH + \"walking_ecg.pkl\", \"rb\") as f:\n",
    "    walking_ecg = pickle.load(f)\n",
    "\n",
    "with gzip.open(DATA_PATH + \"walking_acc.pkl\", \"rb\") as f:\n",
    "    walking_acc = pickle.load(f)\n",
    "walking_acc = walking_acc - np.mean(walking_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(walking_acc), 1, figsize=(20, 20))\n",
    "for idx in range(len(walking_acc)):\n",
    "    peaks, _ = find_peaks(walking_acc[idx], height=PEAK_THRESHOLD)\n",
    "    np.diff(peaks)\n",
    "\n",
    "    ax[idx].plot(walking_acc[idx])\n",
    "    ax[idx].plot(peaks, walking_acc[idx][peaks], \"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_list = list()\n",
    "for idx in range(len(walking_acc)):\n",
    "    peaks, _ = find_peaks(walking_acc[idx], height=PEAK_THRESHOLD)\n",
    "    if peaks == []:\n",
    "        peak_list.append(np.array([0]))\n",
    "    peak_list.append(len(peaks))\n",
    "\n",
    "X_walking = walking_ecg\n",
    "y_walking = peak_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_walking)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running data load\n",
    "with gzip.open(DATA_PATH + \"running_ecg.pkl\", \"rb\") as f:\n",
    "    running_ecg = pickle.load(f)\n",
    "\n",
    "with gzip.open(DATA_PATH + \"running_acc.pkl\", \"rb\") as f:\n",
    "    running_acc = pickle.load(f)\n",
    "running_acc = running_acc - np.mean(running_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(running_acc), 1, figsize=(20, 10))\n",
    "for idx in range(len(running_acc)):\n",
    "    peaks, _ = find_peaks(running_acc[idx], height=PEAK_THRESHOLD)\n",
    "    np.diff(peaks)\n",
    "\n",
    "    ax[idx].plot(running_acc[idx])\n",
    "    ax[idx].plot(peaks, running_acc[idx][peaks], \"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_list = list()\n",
    "for idx in range(len(running_acc)):\n",
    "    peaks, _ = find_peaks(running_acc[idx], height=PEAK_THRESHOLD)\n",
    "    if peaks == []:\n",
    "        peak_list.append(np.array([0]))\n",
    "    peak_list.append(len(peaks))\n",
    "\n",
    "X_running = running_ecg\n",
    "y_running = peak_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X, y data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X_walking, X_running, X_sitting))\n",
    "y = np.concatenate((y_walking, y_running, y_sitting))\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X) ** 2\n",
    "\n",
    "print(f\"\"\"X shape: {X.shape}\n",
    "y shape: {y.shape}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the data\n",
    "fig, ax = plt.subplots(3, 1, figsize=(20, 10))\n",
    "\n",
    "ax[0].title.set_text(y[0])\n",
    "ax[0].plot(X[0])\n",
    "\n",
    "ax[1].title.set_text(y[1])\n",
    "ax[1].plot(X[1])\n",
    "\n",
    "ax[2].title.set_text(y[2])\n",
    "ax[2].plot(X[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('./data//exported/X.pkl', 'wb') as f:\n",
    "    pickle.dump(X, f)\n",
    "\n",
    "with gzip.open('./data//exported/y.pkl', 'wb') as f:\n",
    "    pickle.dump(y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('./data//exported/X.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "with gzip.open('./data//exported/y.pkl', 'rb') as f:\n",
    "    y = pickle.load(f)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(f\"\"\"X_train shape: {X_train.shape}\n",
    "y_train shape: {y_train.shape}\n",
    "X_test shape: {X_test.shape}\n",
    "y_test shape: {y_test.shape}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = np.array(X).astype(np.float32)\n",
    "        self.y = np.array(y).astype(np.float32)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "train_dataset = ECGDataset(X_train, y_train)\n",
    "test_dataset = ECGDataset(X_test, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")\n",
    "EPOCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.nn_layers = nn.ModuleList()\n",
    "        self.nn_layers.append(self.input_block(1, 32, 3, 1, 1)).to(device)\n",
    "        self.nn_layers.append(self.lfem_block(32, 32, 3, 1, 1)).to(device)\n",
    "        self.nn_layers.append(self.lfem_block(32, 64, 3, 1, 1)).to(device)\n",
    "        self.nn_layers.append(self.lfem_block(64, 128, 3, 1, 1)).to(device)\n",
    "        self.nn_layers.append(self.lfem_block(128, 256, 3, 1, 1)).to(device)\n",
    "        self.nn_layers.append(self.lfem_block(256, 256, 3, 1, 1)).to(device)\n",
    "\n",
    "        self.gru = nn.GRU(256, 256, 6, batch_first=True).to(device)\n",
    "        self.fc = nn.Linear(256, 1).to(device)\n",
    "\n",
    "    def input_block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        x = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        ).to(device)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def lfem_block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        x = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "            nn.Conv1d(out_channels, out_channels, kernel_size, stride, padding),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv1d(out_channels, out_channels, 1, stride, padding),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        ).to(device)\n",
    "\n",
    "        return x\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.input_block(1, 32, 3, 1, 1)(x)\n",
    "\n",
    "        x = self.nn_layers[1](x)\n",
    "        x = self.nn_layers[2](x)\n",
    "        x = self.nn_layers[3](x)\n",
    "        x = self.nn_layers[4](x)\n",
    "        x = self.nn_layers[5](x)\n",
    "\n",
    "        x = x.permute(0, 2, 1).to(device)\n",
    "        x, _ = self.gru(x)\n",
    "        x = x[:, -1, :].to(device)\n",
    "\n",
    "        x = self.fc(x).to(device)\n",
    "        x = nn.ReLU()(x).to(device)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "train_loss, val_loss = [], []\n",
    "for epoch in range(EPOCH):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.reshape(-1, 1, 15000).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss.append(running_loss / len(train_dataloader))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(test_dataloader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.unsqueeze(1).to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        val_loss.append(running_loss / len(test_dataloader))\n",
    "    \n",
    "    model.train()\n",
    "    print(f\"Epoch: {epoch + 1} / {EPOCH} | Train loss: {train_loss[-1]:.5f} | Val loss: {val_loss[-1]:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_loss, label=\"Train loss\")\n",
    "plt.plot(val_loss, label=\"Val loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_dataloader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.unsqueeze(1).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        print(f\"Loss: {loss.item():.5f}\")\n",
    "\n",
    "        output_x_range = np.linspace(0, len(outputs.cpu().numpy()), len(outputs.cpu().numpy()))\n",
    "        labels_x_range = np.linspace(0, len(labels.cpu().numpy()), len(labels.cpu().numpy()))\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(output_x_range, outputs.cpu().numpy() * 2, label=\"Predicted\", color=\"red\", marker=\"o\")\n",
    "        plt.plot(labels_x_range, labels.cpu().numpy(), label=\"True\", color=\"blue\", marker=\"*\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
