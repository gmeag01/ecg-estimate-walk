{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.signal import find_peaks\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "np.random.seed(datetime.datetime.now().microsecond)\n",
    "\n",
    "PEAK_THRESHOLD = 390\n",
    "DATA_PATH = \"./data/exported/30sec/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sitting data load\n",
    "with gzip.open(DATA_PATH + \"sitting_ecg.pkl\", \"rb\") as f:\n",
    "    sitting_ecg = pickle.load(f)\n",
    "\n",
    "with gzip.open(DATA_PATH + \"sitting_acc.pkl\", \"rb\") as f:\n",
    "    sitting_acc = pickle.load(f)\n",
    "sitting_acc = sitting_acc - np.mean(sitting_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(sitting_acc), 1, figsize=(20, 10))\n",
    "for idx in range(len(sitting_acc)):\n",
    "    peaks, _ = find_peaks(sitting_acc[idx], height=PEAK_THRESHOLD)\n",
    "    np.diff(peaks)\n",
    "\n",
    "    ax[idx].plot(sitting_acc[idx])\n",
    "    ax[idx].plot(peaks, sitting_acc[idx][peaks], \"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_list = list()\n",
    "for idx in range(len(sitting_acc)):\n",
    "    peaks, _ = find_peaks(sitting_acc[idx], height=PEAK_THRESHOLD)\n",
    "    if peaks == []:\n",
    "        peak_list.append(np.array([0]))\n",
    "    peak_list.append(len(peaks))\n",
    "\n",
    "X_sitting = sitting_ecg\n",
    "y_sitting = peak_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walking data load\n",
    "with gzip.open(DATA_PATH + \"walking_ecg.pkl\", \"rb\") as f:\n",
    "    walking_ecg = pickle.load(f)\n",
    "\n",
    "with gzip.open(DATA_PATH + \"walking_acc.pkl\", \"rb\") as f:\n",
    "    walking_acc = pickle.load(f)\n",
    "walking_acc = walking_acc - np.mean(walking_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(walking_acc), 1, figsize=(20, 20))\n",
    "for idx in range(len(walking_acc)):\n",
    "    peaks, _ = find_peaks(walking_acc[idx], height=PEAK_THRESHOLD)\n",
    "    np.diff(peaks)\n",
    "\n",
    "    ax[idx].plot(walking_acc[idx])\n",
    "    ax[idx].plot(peaks, walking_acc[idx][peaks], \"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_list = list()\n",
    "for idx in range(len(walking_acc)):\n",
    "    peaks, _ = find_peaks(walking_acc[idx], height=PEAK_THRESHOLD)\n",
    "    if peaks == []:\n",
    "        peak_list.append(np.array([0]))\n",
    "    peak_list.append(len(peaks))\n",
    "\n",
    "X_walking = walking_ecg\n",
    "y_walking = peak_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_walking)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running data load\n",
    "with gzip.open(DATA_PATH + \"running_ecg.pkl\", \"rb\") as f:\n",
    "    running_ecg = pickle.load(f)\n",
    "\n",
    "with gzip.open(DATA_PATH + \"running_acc.pkl\", \"rb\") as f:\n",
    "    running_acc = pickle.load(f)\n",
    "running_acc = running_acc - np.mean(running_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(running_acc), 1, figsize=(20, 10))\n",
    "for idx in range(len(running_acc)):\n",
    "    peaks, _ = find_peaks(running_acc[idx], height=PEAK_THRESHOLD)\n",
    "    np.diff(peaks)\n",
    "\n",
    "    ax[idx].plot(running_acc[idx])\n",
    "    ax[idx].plot(peaks, running_acc[idx][peaks], \"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_list = list()\n",
    "for idx in range(len(running_acc)):\n",
    "    peaks, _ = find_peaks(running_acc[idx], height=PEAK_THRESHOLD)\n",
    "    if peaks == []:\n",
    "        peak_list.append(np.array([0]))\n",
    "    peak_list.append(len(peaks))\n",
    "\n",
    "X_running = running_ecg\n",
    "y_running = peak_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X, y data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X_walking, X_running))\n",
    "y = np.concatenate((y_walking, y_running))\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "# y = scaler.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "print(f\"\"\"X shape: {X.shape}\n",
    "y shape: {y.shape}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_idx = np.random.randint(0, len(X), 3)\n",
    "\n",
    "# Plotting the data\n",
    "fig, ax = plt.subplots(3, 1, figsize=(20, 10))\n",
    "\n",
    "for idx in range(3):\n",
    "    ax[idx].plot(X[plotting_idx[idx]])\n",
    "    ax[idx].set_title(f\"Peak count: {y[plotting_idx[idx]]}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('./data//exported/X.pkl', 'wb') as f:\n",
    "    pickle.dump(X, f)\n",
    "\n",
    "with gzip.open('./data//exported/y.pkl', 'wb') as f:\n",
    "    pickle.dump(y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('./data//exported/X.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "with gzip.open('./data//exported/y.pkl', 'rb') as f:\n",
    "    y = pickle.load(f)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=datetime.datetime.now().microsecond)\n",
    "\n",
    "print(f\"\"\"X_train shape: {X_train.shape}\n",
    "y_train shape: {y_train.shape}\n",
    "X_test shape: {X_test.shape}\n",
    "y_test shape: {y_test.shape}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = np.array(X).astype(np.float32)\n",
    "        self.y = np.array(y).astype(np.float32)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "train_dataset = ECGDataset(X_train, y_train)\n",
    "test_dataset = ECGDataset(X_test, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")\n",
    "EPOCH = 70\n",
    "MODEL_SAVE_PATH = \"./model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseModel, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(X_train.shape[1], 4096)\n",
    "        self.fc1_2 = nn.Linear(4096, 2048)\n",
    "        self.fc1_1 = nn.Linear(2048, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 64)\n",
    "        self.fc6 = nn.Linear(64, 32)\n",
    "        self.fc7 = nn.Linear(32, 16)\n",
    "        self.fc8 = nn.Linear(16, 1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc1_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc1_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc6(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc7(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc8(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseModel().to(device)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "train_loss, val_loss = [], []\n",
    "for epoch in range(EPOCH):\n",
    "    running_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=f\"Epoch: {epoch + 1} / {EPOCH}\"):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.reshape(-1, 1, 7500).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss.append(running_loss / len(train_dataloader))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(test_dataloader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.unsqueeze(1).to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        val_loss.append(running_loss / len(test_dataloader))\n",
    "    \n",
    "    print(f\"Epoch: {epoch + 1} / {EPOCH} | Train loss: {train_loss[-1]:.5f} | Val loss: {val_loss[-1]:.5f}\")\n",
    "    \n",
    "    # Model save\n",
    "    if val_loss[-1] == min(val_loss):\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH + f\"model_{epoch + 1}_{val_loss[-1]:.5f}.pth\")\n",
    "        print(f\"Model saved at Epoch: {epoch + 1}, Val loss: {val_loss[-1]:.5f}\")\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_loss, label=\"Train loss\")\n",
    "plt.plot(val_loss, label=\"Val loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "output_list, label_list = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_dataloader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.unsqueeze(1).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        output_list.append(outputs.item())\n",
    "        label_list.append(labels.item())\n",
    "\n",
    "        print(f\"Loss: {loss:.5f}\\t\\tPredicted: {outputs.item()}\\t\\tActual: {labels.item():.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(output_list, label=\"Predicted\", marker=\"o\", linestyle=\"None\", color=\"red\")\n",
    "plt.plot(label_list, label=\"Actual\", marker=\"*\", linestyle=\"None\", color=\"blue\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
